<!DOCTYPE html>


<html lang="zh-CN">


<head>
  <meta charset="utf-8" />
    
  <meta name="description" content="好记性不如烂笔头" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    大数据课程课前环境准备 |  奋斗的皮皮虾
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/images/avatar.jpg" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

  

<link rel="alternate" href="/atom.xml" title="奋斗的皮皮虾" type="application/atom+xml">
</head>

</html>

<body>
  <div id="app">
    
      <canvas class="fireworks"></canvas>
      <style>
        .fireworks {
          position: fixed;
          left: 0;
          top: 0;
          z-index: 99999;
          pointer-events: none;
        }
      </style>
      
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-大数据课程课前环境准备"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  大数据课程课前环境准备
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/09/29/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E8%AF%BE%E5%89%8D%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/" class="article-date">
  <time datetime="2020-09-28T17:14:23.000Z" itemprop="datePublished">2020-09-29</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">5.9k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">25 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="大数据课程课前环境准备"><a href="#大数据课程课前环境准备" class="headerlink" title="大数据课程课前环境准备"></a>大数据课程课前环境准备</h1><h2 id="一、课前准备"><a href="#一、课前准备" class="headerlink" title="一、课前准备"></a>一、课前准备</h2><ol>
<li>准备一台内存最少8G（建议16G）、cpu i7 4核的电脑</li>
</ol>
<h2 id="二、课堂主题"><a href="#二、课堂主题" class="headerlink" title="二、课堂主题"></a>二、课堂主题</h2><ol>
<li>安装虚拟化软件VMware</li>
<li>准备3台linux虚拟机</li>
<li>搭建3节点zookeeper集群</li>
<li>搭建3节点的hadoop集群</li>
</ol>
<h2 id="三、课堂目标"><a href="#三、课堂目标" class="headerlink" title="三、课堂目标"></a>三、课堂目标</h2><ol>
<li>完成大数据课程课前环境准备</li>
</ol>
<h2 id="四、知识要点"><a href="#四、知识要点" class="headerlink" title="四、知识要点"></a>四、知识要点</h2><blockquote>
<h3 id="文档说明："><a href="#文档说明：" class="headerlink" title="文档说明："></a>文档说明：</h3><ul>
<li>在学习大数据课程的全程中，要求大家统一保持跟老师一样的操作系统、软件版本、环境设置</li>
</ul>
<h3 id="VMware版本："><a href="#VMware版本：" class="headerlink" title="VMware版本："></a>VMware版本：</h3><ul>
<li>VMware建议使用比较新的版本，如VMware 15.5</li>
<li>关于VMware的安装，直接使用安装包一直下一步安装即可，且安装包当中附带破解秘钥，进行破解即可使用</li>
</ul>
<h3 id="linux版本"><a href="#linux版本" class="headerlink" title="linux版本"></a>linux版本</h3><ul>
<li><p>linux统一使用centos7.6  64位版本</p>
</li>
<li><p>种子文件下载地址：<a href="http://mirrors.aliyun.com/centos/7.6.1810/isos/x86_64/CentOS-7-x86_64-DVD-1810.torrent" target="_blank" rel="noopener">http://mirrors.aliyun.com/centos/7.6.1810/isos/x86_64/CentOS-7-x86_64-DVD-1810.torrent</a></p>
</li>
<li><p><font color='red'>具体实操过程请参考视频</font></p>
</li>
</ul>
</blockquote>
<h3 id="1-三台linux服务器的安装"><a href="#1-三台linux服务器的安装" class="headerlink" title="1. 三台linux服务器的安装"></a>1. 三台linux服务器的安装</h3><h4 id="1-安装VMware"><a href="#1-安装VMware" class="headerlink" title="1. 安装VMware"></a>1. 安装VMware</h4><ul>
<li><p>VMware虚拟机软件是一个“虚拟<a href="https://baike.baidu.com/item/PC/107" target="_blank" rel="noopener">PC</a>”软件，它使你可以在一台机器上同时运行二个或更多<a href="https://baike.baidu.com/item/Windows" target="_blank" rel="noopener">Windows</a>、<a href="https://baike.baidu.com/item/DOS/32025" target="_blank" rel="noopener">DOS</a>、<a href="https://baike.baidu.com/item/LINUX" target="_blank" rel="noopener">LINUX</a>系统。与“多启动”系统相比，<a href="https://baike.baidu.com/item/VMWare" target="_blank" rel="noopener">VMWare</a>采用了完全不同的概念。</p>
</li>
<li><p>我们可以通过VMware来安装我们的linux虚拟机，然后通过linux虚拟机来进行集群的安装，VMware的安装双击之后，一路下一步即可，尽量不要装在操作系统盘里面了，VMware的安装步骤省略</p>
<img src="../images/assets/vm.png" style="zoom:80%;" />

</li>
</ul>
<h4 id="2-通过Vmware安装第一台linux机器"><a href="#2-通过Vmware安装第一台linux机器" class="headerlink" title="2. 通过Vmware安装第一台linux机器"></a>2. 通过Vmware安装第一台linux机器</h4><ul>
<li>我们通过Vmware可以安装第一台我们的linux机器，接下来我们来看如何通过VMWare创建linux虚拟机，并给我们的虚拟机挂载操作系统</li>
</ul>
<p>1：双击Vmware打开之后，点击创建新的虚拟机</p>
<p><img src="../images/assets/1.png" alt=""></p>
<p>2：选择自定义安装配置</p>
<p><img src="../images/assets/2.png" alt=""></p>
<p><img src="../images/assets/image-20200513103314891.png" alt="image-20200513103314891"></p>
<p>3：选择稍后安装操作系统</p>
<p><img src="../images/assets/4.png" alt=""></p>
<p>4：选择稍后安装操作系统</p>
<p><img src="../images/assets/5.png" alt=""></p>
<p>5：选择安装路径，==尽量不要放在C盘，并且所在盘符的剩余空间尽量大些==</p>
<p><img src="../images/assets/image-20200513103635615.png" alt="image-20200513103635615"></p>
<p>6：CPU核数，默认即可</p>
<p><img src="../images/assets/7.png" alt=""></p>
<p>7：虚拟机内存根据自身windows电脑进行调整</p>
<p>例如如果windows是8GB内存，那么每台虚拟机内存给2048M内存，如果windows是16GB没存，那么每台虚拟机可以给3072M内存即可</p>
<p><img src="../images/assets/8.png" alt=""></p>
<p>8：网络配置一定要选择==NAT==</p>
<p><img src="../images/assets/9.png" alt=""></p>
<p><img src="../images/assets/10.png" alt=""></p>
<p><img src="../images/assets/11.png" alt=""></p>
<p>9：磁盘大小尽量给40GB</p>
<p><img src="../images/assets/12.png" alt=""></p>
<p>注意：千万==不要==勾选“立即分配所有磁盘空间”</p>
<p><img src="../images/assets/13.png" alt=""></p>
<p><img src="../images/assets/image-20200513104013911.png" alt="image-20200513104013911"></p>
<p>10：完成</p>
<p><img src="../images/assets/image-20200513104053651.png" alt="image-20200513104053651"></p>
<h4 id="3-为我们创建的linux虚拟机挂载操作系统"><a href="#3-为我们创建的linux虚拟机挂载操作系统" class="headerlink" title="3. 为我们创建的linux虚拟机挂载操作系统"></a>3. 为我们创建的linux虚拟机挂载操作系统</h4><ul>
<li>我们现在已经有了一台虚拟电脑了，就类似我们刚刚买了一台电脑回来，只不过不同的是我们这台虚拟电脑还没有操作系统我们需要为这台电脑挂在操作系统出来</li>
</ul>
<p>1：通过设置来挂载操作系统</p>
<p><img src="../images/assets/16.png" alt=""></p>
<p><img src="../images/assets/17.png" alt=""></p>
<p><img src="../images/assets/18.png" alt=""></p>
<p>2：直接回车开始安装</p>
<p>用键盘的方向键，选中“Install CentOS 7”,然后按回车，开始安装</p>
<p><img src="../images/assets/image-20200715134015711.png" alt="image-20200715134015711"></p>
<p>再按回车键</p>
<p><img src="../images/assets/19.png" alt=""></p>
<p>3：设置键盘为英文键盘</p>
<p><img src="../images/assets/image-20201021111652532.png" alt="image-20201021111652532"></p>
<p>4：接下来配置这三项</p>
<p><img src="../images/assets/21.png" alt=""></p>
<p>（1）设置①时区为Asia/Shanghai</p>
<p><img src="../images/assets/22.png" alt=""></p>
<p><img src="../images/assets/image-20201021111858683.png" alt="image-20201021111858683"></p>
<p>（2）设置②INSTALATION DESTINATION</p>
<p><img src="../images/assets/image-20201021112000200.png" alt="image-20201021112000200"></p>
<p><img src="../images/assets/23.png" alt=""></p>
<p>（3）设置③NETWORK &amp; HOST NAME</p>
<p><img src="../images/assets/image-20200513105009692.png" alt="image-20200513105009692"></p>
<p>5：设置root用户密码</p>
<p><img src="../images/assets/26.png" alt=""></p>
<p>6：安装完成之后重启reboot即可</p>
<p>此过程稍长，耐心等待</p>
<p><img src="../images/assets/image-20200513105644118.png" alt="image-20200513105644118"></p>
<h4 id="4-为我们的linux虚拟机设置网络配置"><a href="#4-为我们的linux虚拟机设置网络配置" class="headerlink" title="4. 为我们的linux虚拟机设置网络配置"></a>4. 为我们的linux虚拟机设置网络配置</h4><ul>
<li>我们的linux虚拟机已经创建并挂载好了操作系统，接下来我们可以为我们的第一台虚拟机来设置网络地址了，设置网络地址比较麻烦，尽量<strong>参见视频</strong>进行一步步的操作</li>
</ul>
<p>1：设置虚拟机的网段</p>
<p><img src="../images/assets/28.png" alt=""></p>
<p>2：查看==NAT模式==的网关，子网IP以及子网掩码</p>
<p><img src="../images/assets/image-20201019113303256.png" alt="image-20201019113303256"></p>
<p>3：设置window当中的VMNet8网络地址</p>
<p><img src="../images/assets/30.png" alt=""></p>
<p><img src="../images/assets/image-20201019114244290.png" alt="image-20201019114244290"></p>
<p>4：设置linux当中的网络</p>
<ul>
<li><p>我们已经配置好了Vmware当中的网络、windows当中的网络；</p>
</li>
<li><p>剩下就是配置linux虚拟机当中的网络，配置好了linux当中的网络，我们的linux就可以联网使用了</p>
</li>
<li><p>登录linux</p>
</li>
</ul>
<p><img src="../images/assets/32.png" alt=""></p>
<p>编辑配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sysconfig/network-scripts/ifcfg-ens33</span><br></pre></td></tr></table></figure>

<p>添加联网四要素</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">IPADDR</span>=<span class="string">192.168.51.100</span></span><br><span class="line"><span class="attr">NETMASK</span>=<span class="string">255.255.255.0</span></span><br><span class="line"><span class="attr">GATEWAY</span>=<span class="string">192.168.51.1</span></span><br><span class="line"><span class="attr">DNS1</span>=<span class="string">8.8.8.8</span></span><br></pre></td></tr></table></figure>

<p>具体参考下图</p>
<p><img src="../images/assets/image-20201019114510503.png" alt="image-20201019114510503"></p>
<p>更改完成配置，重启网络服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart network</span><br></pre></td></tr></table></figure>

<p>安装一些常用的软件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum -y install vim</span><br><span class="line">yum -y install net-tools</span><br></pre></td></tr></table></figure>

<p>关机</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">init 0</span><br></pre></td></tr></table></figure>



<h4 id="5-克隆第一台机器"><a href="#5-克隆第一台机器" class="headerlink" title="5. 克隆第一台机器"></a>5. 克隆第一台机器</h4><ul>
<li><p>现在我们已经有了种子机器了，我们可以通过种子机器进行复制或者克隆出三台机器</p>
</li>
<li><p>关闭linux种子机器，然后准备进行克隆</p>
</li>
</ul>
<p><img src="../images/assets/34.png" alt=""></p>
<p><img src="../images/assets/image-20200513111624820.png" alt="image-20200513111624820"></p>
<p><img src="../images/assets/35.png" alt=""></p>
<p>选择创建完整克隆</p>
<p><img src="../images/assets/36.png" alt=""></p>
<p><img src="../images/assets/image-20200513111854167.png" alt="image-20200513111854167"></p>
<h4 id="6-更改克隆机器的IP地址"><a href="#6-更改克隆机器的IP地址" class="headerlink" title="6. 更改克隆机器的IP地址"></a>6. 更改克隆机器的IP地址</h4><ul>
<li><p>三台机器的ip地址分别是<code>192.168.51.100、192.168.51.110、192.168.51.120</code></p>
</li>
<li><p>克隆出来的机器IP地址与种子的ip地址一样，我们将第二台机器的IP地址更改为192.168.51.110即可</p>
</li>
<li><p>启动虚拟机，并通过root用户，密码123456来进行登录，然后来更改linux机器的IP地址</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sysconfig/network-scripts/ifcfg-ens33</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">IPADDR=192.168.51.110</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line">GATEWAY=192.168.51.1</span><br><span class="line">DNS1=8.8.8.8</span><br></pre></td></tr></table></figure>

<ul>
<li><p>依照上面步骤，接着克隆第三台机器，并将第三台机器的IP地址设置为</p>
<p>192.168.51.120</p>
</li>
</ul>
<p><font color='red'>建议：三台机器准备好后，打个快照，便于出错后恢复</font></p>
<h3 id="2-安装大数据集群前的环境准备"><a href="#2-安装大数据集群前的环境准备" class="headerlink" title="2. 安装大数据集群前的环境准备"></a>2. 安装大数据集群前的环境准备</h3><h4 id="1-三台虚拟机关闭防火墙"><a href="#1-三台虚拟机关闭防火墙" class="headerlink" title="1. 三台虚拟机关闭防火墙"></a>1. 三台虚拟机关闭防火墙</h4><p>三台机器执行以下命令（<font color='red'>root</font>用户来执行）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure>



<h4 id="2-三台机器关闭selinux"><a href="#2-三台机器关闭selinux" class="headerlink" title="2. 三台机器关闭selinux"></a>2. 三台机器关闭selinux</h4><p>三台机器执行以下命令关闭selinux</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sysconfig/selinux</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELINUX=disabled</span><br></pre></td></tr></table></figure>



<h4 id="3-三台机器更改主机名"><a href="#3-三台机器更改主机名" class="headerlink" title="3. 三台机器更改主机名"></a>3. 三台机器更改主机名</h4><p>三台机器执行以下命令更改主机名</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/hostname</span><br></pre></td></tr></table></figure>

<p>第一台机器更改内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node01.kaikeba.com</span><br></pre></td></tr></table></figure>

<p>第二台机器更改内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node02.kaikeba.com</span><br></pre></td></tr></table></figure>

<p>第三台机器更改内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node03.kaikeba.com</span><br></pre></td></tr></table></figure>



<h4 id="4-三台机器做主机名与IP地址的映射"><a href="#4-三台机器做主机名与IP地址的映射" class="headerlink" title="4. 三台机器做主机名与IP地址的映射"></a>4. 三台机器做主机名与IP地址的映射</h4><p>三台机器执行以下命令更改主机名与IP地址的映射</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/hosts</span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.51.100 node01.kaikeba.com node01</span><br><span class="line">192.168.51.110 node02.kaikeba.com node02</span><br><span class="line">192.168.51.120 node03.kaikeba.com node03</span><br></pre></td></tr></table></figure>



<h4 id="5-三台机器时钟同步"><a href="#5-三台机器时钟同步" class="headerlink" title="5. 三台机器时钟同步"></a>5. 三台机器时钟同步</h4><h5 id="第一种同步方式：通过网络进行时钟同步"><a href="#第一种同步方式：通过网络进行时钟同步" class="headerlink" title="第一种同步方式：通过网络进行时钟同步"></a>第一种同步方式：通过网络进行时钟同步</h5><p>通过网络连接外网进行时钟同步,必须保证虚拟机连上外网</p>
<p>三台机器都安装ntpdate</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install ntpdate</span><br></pre></td></tr></table></figure>

<p>阿里云时钟同步服务器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ntpdate ntp4.aliyun.com</span><br></pre></td></tr></table></figure>

<p>三台机器定时任务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crontab -e</span><br></pre></td></tr></table></figure>

<p>添加如下内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * /usr/sbin/ntpdate ntp4.aliyun.com;</span><br></pre></td></tr></table></figure>

<h5 id="第二种同步方式：内网某机器作为时钟同步服务器"><a href="#第二种同步方式：内网某机器作为时钟同步服务器" class="headerlink" title="第二种同步方式：内网某机器作为时钟同步服务器"></a>第二种同步方式：内网某机器作为时钟同步服务器</h5><p><font color='red'>以下操作都在root用户下面执行，通过su root切换到root用户</font></p>
<p>以192.168.51.100这台服务器的时间为准进行时钟同步</p>
<h6 id="第一步-三台机器确定是否安装了ntpd的服务"><a href="#第一步-三台机器确定是否安装了ntpd的服务" class="headerlink" title="第一步:三台机器确定是否安装了ntpd的服务"></a>第一步:三台机器确定是否安装了ntpd的服务</h6><p>三台机器确认是否安装ntpdate时钟同步工具</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa | grep ntpdate</span><br></pre></td></tr></table></figure>

<p>如果没有安装,三台机器执行以下命令可以进行在线安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install ntpdate</span><br></pre></td></tr></table></figure>

<p>安装后如下图</p>
<p><img src="../images/assets/38.png" alt=""></p>
<p>node01安装ntp</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install ntp</span><br></pre></td></tr></table></figure>

<p>三台机器，执行以下命令，设置时区为中国上海时区</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">timedatectl set-timezone Asia/Shanghai</span><br></pre></td></tr></table></figure>

<h6 id="第二步：node01启动ntpd服务"><a href="#第二步：node01启动ntpd服务" class="headerlink" title="第二步：node01启动ntpd服务"></a>第二步：node01启动ntpd服务</h6><p>我们需要启动node01的ntpd服务，作为服务端，对外提供同步时间的服务</p>
<p>启动ntpd的服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">启动ntpd服务</span></span><br><span class="line">systemctl start ntpd</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">设置ntpd服务开机启动</span></span><br><span class="line">systemctl enable ntpd</span><br></pre></td></tr></table></figure>



<h6 id="第三步：修改node01服务器配置"><a href="#第三步：修改node01服务器配置" class="headerlink" title="第三步：修改node01服务器配置"></a>第三步：修改node01服务器配置</h6><p>修改node01这台服务器的时钟同步配置，允许对外提供服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/ntp.conf</span><br></pre></td></tr></table></figure>

<p><font color='red'>添加以下两行内容</font></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 同意192.168.51.0网段（修改成自己的网段）的所有机器与node01同步时间</span></span><br><span class="line">restrict 192.168.51.0 mask 255.255.255.0 nomodify notrap</span><br><span class="line">server 127.127.1.0</span><br></pre></td></tr></table></figure>

<p><font color='red'>注释掉以下这四行内容</font></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">server 0.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="meta">#</span><span class="bash">server 1.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="meta">#</span><span class="bash">server 2.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="meta">#</span><span class="bash">server 3.centos.pool.ntp.org iburst</span></span><br></pre></td></tr></table></figure>

<p> <img src="../images/assets/39.png" alt=""></p>
<p>修改完成之后，重启node01的ntpd服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart ntpd</span><br></pre></td></tr></table></figure>

<p>至此，ntpd的服务端已经安装配置完成，接下来配置客户端与服务端进行同步</p>
<h6 id="第四步：配置node02与node03同步node01的时间"><a href="#第四步：配置node02与node03同步node01的时间" class="headerlink" title="第四步：配置node02与node03同步node01的时间"></a>第四步：配置node02与node03同步node01的时间</h6><p>客户端node02与node03设置时区与node01保持一致Asia/Shanghai</p>
<p>node02与node03修改配置文件，保证每次时间写入硬件时钟</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysconfig/ntpdate</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SYNC_HWCLOCK=yes</span><br></pre></td></tr></table></figure>

<p>node02与node03修改定时任务，定时与node01同步时间</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node03 hadoop]# crontab -e</span><br></pre></td></tr></table></figure>

<p> 增加如下内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * /usr/sbin/ntpdate node01</span><br></pre></td></tr></table></figure>



<h4 id="6-三台机器添加普通用户"><a href="#6-三台机器添加普通用户" class="headerlink" title="6. 三台机器添加普通用户"></a>6. 三台机器添加普通用户</h4><p>三台linux服务器统一添加普通用户hadoop，并给以sudo权限，用于以后所有的大数据软件的安装</p>
<p>并统一设置普通用户的密码为 ==123456==</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">useradd hadoop</span><br><span class="line">passwd hadoop</span><br></pre></td></tr></table></figure>

<p>普通用户的密码设置为123456</p>
<p>三台机器为普通用户添加sudo权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">visudo</span><br></pre></td></tr></table></figure>

<p> 增加如下内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop ALL=(ALL)    ALL</span><br></pre></td></tr></table></figure>



<h4 id="7-三台定义统一目录"><a href="#7-三台定义统一目录" class="headerlink" title="7. 三台定义统一目录"></a>7. 三台定义统一目录</h4><p>定义三台linux服务器软件压缩包存放目录，以及解压后安装目录，三台机器执行以下命令，创建两个文件夹，一个用于存放软件压缩包目录，一个用于存放解压后目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /kkb/soft   # 软件压缩包存放目录</span><br><span class="line">mkdir -p /kkb/install # 软件解压后存放目录</span><br><span class="line">chown -R hadoop:hadoop /kkb  # 将文件夹权限更改为hadoop用户</span><br></pre></td></tr></table></figure>



<p><font color='red'>创建hadoop用户之后，我们三台机器都通过hadoop用户来进行操作，以后再也不需要使用root用户来操作了</font></p>
<p><font color='red'>三台机器通过 su hadoop命令来切换到hadoop用户</font></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">su hadoop</span><br></pre></td></tr></table></figure>



<h4 id="8-三台机器hadoop用户免密码登录"><a href="#8-三台机器hadoop用户免密码登录" class="headerlink" title="8. 三台机器hadoop用户免密码登录"></a>8. 三台机器hadoop用户免密码登录</h4><p>重启下3个linux虚拟机，让主机名生效</p>
<p>第一步：三台机器在<font color='red'>hadoop</font>用户下执行以下命令生成公钥与私钥</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>

<p><font color='red'>执行上述命令之后，按三次Enter键即可生成了</font></p>
<p>第二步：三台机器在hadoop用户下，执行命令拷贝公钥到node01服务器</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id node01</span><br></pre></td></tr></table></figure>



<p>第三步：node01服务器将公钥拷贝给node02与node03</p>
<p>node01在hadoop用户下，执行以下命令，将authorized_keys拷贝到node02与node03服务器</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop/.ssh/</span><br><span class="line">scp authorized_keys node02:$PWD</span><br><span class="line">scp authorized_keys node03:$PWD</span><br></pre></td></tr></table></figure>



<p>第四步：验证；从任意节点是否能免秘钥登陆其他节点；如node01免密登陆node02</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh node02</span><br></pre></td></tr></table></figure>



<h4 id="9-三台机器关机重启"><a href="#9-三台机器关机重启" class="headerlink" title="9. 三台机器关机重启"></a>9. 三台机器关机重启</h4><p>三台机器在hadoop用户下执行以下命令，实现关机重启</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo reboot -h now</span><br></pre></td></tr></table></figure>



<h4 id="10-三台机器安装jdk"><a href="#10-三台机器安装jdk" class="headerlink" title="10. 三台机器安装jdk"></a>10. 三台机器安装jdk</h4><ul>
<li><p>使用hadoop用户来重新连接三台机器，然后使用hadoop用户来安装jdk软件</p>
</li>
<li><p>上传压缩包到第一台服务器的/kkb/soft下面，然后进行解压，配置环境变量即可，三台机器都依次安装即可</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /kkb/soft/ </span><br><span class="line">tar -xzvf jdk-8u141-linux-x64.tar.gz -C /kkb/install/</span><br><span class="line">sudo vim /etc/profile</span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">添加以下配置内容，配置jdk环境变量</span></span><br><span class="line">export JAVA_HOME=/kkb/install/jdk1.8.0_141</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure>

<p>让修改马上生效</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>

<p><font color='red'>建议：三台机器准备好后，打个快照，便于出错后恢复</font></p>
<h3 id="3-hadoop集群的安装"><a href="#3-hadoop集群的安装" class="headerlink" title="3. hadoop集群的安装"></a>3. hadoop集群的安装</h3><ul>
<li>安装环境服务部署规划</li>
</ul>
<table>
<thead>
<tr>
<th>服务器IP</th>
<th>node01</th>
<th>node02</th>
<th>node03</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>NameNode</td>
<td></td>
<td></td>
</tr>
<tr>
<td>HDFS</td>
<td>SecondaryNameNode</td>
<td></td>
<td></td>
</tr>
<tr>
<td>HDFS</td>
<td>DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
<tr>
<td>YARN</td>
<td>ResourceManager</td>
<td></td>
<td></td>
</tr>
<tr>
<td>YARN</td>
<td>NodeManager</td>
<td>NodeManager</td>
<td>NodeManager</td>
</tr>
<tr>
<td>历史日志服务器</td>
<td>JobHistoryServer</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h5 id="第一步：上传压缩包并解压"><a href="#第一步：上传压缩包并解压" class="headerlink" title="第一步：上传压缩包并解压"></a>第一步：上传压缩包并解压</h5><ul>
<li>将我们重新编译之后支持snappy压缩的hadoop包上传到第一台服务器并解压；第一台机器执行以下命令</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /kkb/soft/</span><br><span class="line">tar -xzvf hadoop-3.1.4.tar.gz -C /kkb/install</span><br></pre></td></tr></table></figure>



<h5 id="第二步：查看hadoop支持的压缩方式以及本地库"><a href="#第二步：查看hadoop支持的压缩方式以及本地库" class="headerlink" title="第二步：查看hadoop支持的压缩方式以及本地库"></a>第二步：查看hadoop支持的压缩方式以及本地库</h5><p>第一台机器执行以下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /kkb/install/hadoop-3.1.4/</span><br><span class="line">bin/hadoop checknative</span><br></pre></td></tr></table></figure>

<p>如果出现openssl为false，那么==所有机器==在线安装openssl即可，执行以下命令，虚拟机联网之后就可以在线进行安装了</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum -y install openssl-devel</span><br></pre></td></tr></table></figure>



<h5 id="第三步：修改配置文件"><a href="#第三步：修改配置文件" class="headerlink" title="第三步：修改配置文件"></a>第三步：修改配置文件</h5><h6 id="修改hadoop-env-sh"><a href="#修改hadoop-env-sh" class="headerlink" title="修改hadoop-env.sh"></a>修改hadoop-env.sh</h6><p>第一台机器执行以下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /kkb/install/hadoop-3.1.4/etc/hadoop/</span><br><span class="line">vim hadoop-env.sh</span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/kkb/install/jdk1.8.0_141</span><br></pre></td></tr></table></figure>

<h6 id="修改core-site-xml"><a href="#修改core-site-xml" class="headerlink" title="修改core-site.xml"></a>修改core-site.xml</h6><p>第一台机器执行以下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim core-site.xml</span><br></pre></td></tr></table></figure>



<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>



<h6 id="修改hdfs-site-xml"><a href="#修改hdfs-site-xml" class="headerlink" title="修改hdfs-site.xml"></a>修改hdfs-site.xml</h6><p>第一台机器执行以下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hdfs-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- NameNode存储元数据信息的路径，实际工作中，一般先确定磁盘的挂载目录，然后多个目录用，进行分割   --&gt;</span> </span><br><span class="line">    <span class="comment">&lt;!--   集群动态上下线 </span></span><br><span class="line"><span class="comment">    &lt;property&gt;</span></span><br><span class="line"><span class="comment">        &lt;name&gt;dfs.hosts&lt;/name&gt;</span></span><br><span class="line"><span class="comment">        &lt;value&gt;/kkb/install/hadoop-3.1.4/etc/hadoop/accept_host&lt;/value&gt;</span></span><br><span class="line"><span class="comment">    &lt;/property&gt;</span></span><br><span class="line"><span class="comment">    &lt;property&gt;</span></span><br><span class="line"><span class="comment">        &lt;name&gt;dfs.hosts.exclude&lt;/name&gt;</span></span><br><span class="line"><span class="comment">        &lt;value&gt;/kkb/install/hadoop-3.1.4/etc/hadoop/deny_host&lt;/value&gt;</span></span><br><span class="line"><span class="comment">    &lt;/property&gt;</span></span><br><span class="line"><span class="comment">     --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- namenode保存fsimage的路径 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///kkb/install/hadoop-3.1.4/hadoopDatas/namenodeDatas<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  定义dataNode数据存储的节点位置，实际工作中，一般先确定磁盘的挂载目录，然后多个目录用，进行分割  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///kkb/install/hadoop-3.1.4/hadoopDatas/datanodeDatas<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- namenode保存editslog的目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///kkb/install/hadoop-3.1.4/hadoopDatas/dfs/nn/edits<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- secondarynamenode保存待合并的fsimage --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///kkb/install/hadoop-3.1.4/hadoopDatas/dfs/snn/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- secondarynamenode保存待合并的editslog --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///kkb/install/hadoop-3.1.4/hadoopDatas/dfs/nn/snn/edits<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.blocksize<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h6 id="修改mapred-site-xml"><a href="#修改mapred-site-xml" class="headerlink" title="修改mapred-site.xml"></a>修改mapred-site.xml</h6><p>第一台机器执行以下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim mapred-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h6 id="修改yarn-site-xml"><a href="#修改yarn-site-xml" class="headerlink" title="修改yarn-site.xml"></a>修改yarn-site.xml</h6><p>第一台机器执行以下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim yarn-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h6 id="修改workers文件"><a href="#修改workers文件" class="headerlink" title="修改workers文件"></a>修改workers文件</h6><p>第一台机器执行以下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim workers</span><br></pre></td></tr></table></figure>

<p>原内容替换为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node01</span><br><span class="line">node02</span><br><span class="line">node03</span><br></pre></td></tr></table></figure>

<h5 id="第四步：创建文件存放目录"><a href="#第四步：创建文件存放目录" class="headerlink" title="第四步：创建文件存放目录"></a>第四步：创建文件存放目录</h5><p>第一台机器执行以下命令</p>
<p>node01机器上面创建以下目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /kkb/install/hadoop-3.1.4/hadoopDatas/tempDatas</span><br><span class="line">mkdir -p /kkb/install/hadoop-3.1.4/hadoopDatas/namenodeDatas</span><br><span class="line">mkdir -p /kkb/install/hadoop-3.1.4/hadoopDatas/datanodeDatas </span><br><span class="line">mkdir -p /kkb/install/hadoop-3.1.4/hadoopDatas/dfs/nn/edits</span><br><span class="line">mkdir -p /kkb/install/hadoop-3.1.4/hadoopDatas/dfs/snn/name</span><br><span class="line">mkdir -p /kkb/install/hadoop-3.1.4/hadoopDatas/dfs/nn/snn/edits</span><br></pre></td></tr></table></figure>



<h5 id="第五步：安装包的分发scp与rsync"><a href="#第五步：安装包的分发scp与rsync" class="headerlink" title="第五步：安装包的分发scp与rsync"></a>第五步：安装包的分发scp与rsync</h5><p>在linux当中，用于向远程服务器拷贝文件或者文件夹可以使用scp或者rsync，这两个命令功能类似都是向远程服务器进行拷贝，只不过scp是全量拷贝，rsync可以做到增量拷贝，rsync的效率比scp更高一些</p>
<h6 id="1-通过scp直接拷贝"><a href="#1-通过scp直接拷贝" class="headerlink" title="1. 通过scp直接拷贝"></a>1. 通过scp直接拷贝</h6><p>scp（secure copy）安全拷贝</p>
<p>可以通过scp进行不同服务器之间的文件或者文件夹的复制</p>
<p>使用语法 </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r sourceFile  username@host:destpath</span><br></pre></td></tr></table></figure>

<p>用法示例</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r hadoop-lzo-0.4.20.jar hadoop@node01:/kkb/</span><br></pre></td></tr></table></figure>

<p>node01执行以下命令进行拷贝</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /kkb/install/</span><br><span class="line">scp -r hadoop-3.1.4/ node02:$PWD</span><br><span class="line">scp -r hadoop-3.1.4/ node03:$PWD</span><br></pre></td></tr></table></figure>



<h6 id="2-通过rsync来实现增量拷贝"><a href="#2-通过rsync来实现增量拷贝" class="headerlink" title="2. 通过rsync来实现增量拷贝"></a>2. 通过rsync来实现增量拷贝</h6><p>rsync 远程同步工具</p>
<p>rsync主要用于备份和镜像。具有速度快、<font color='red'>避免复制相同内容</font>和支持符号链接的优点。</p>
<p>rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。</p>
<p><font color='red'>三台机器执行以下命令安装rsync工具</font></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum -y install rsync</span><br></pre></td></tr></table></figure>

<p>（1）  基本语法</p>
<p>node01执行以下命令同步zk安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -av /kkb/soft/apache-zookeeper-3.6.2-bin.tar.gz node02:/kkb/soft/</span><br></pre></td></tr></table></figure>

<p>命令 选项参数 要拷贝的文件路径/名称 目的用户@主机:目的路径/名称</p>
<p>选项参数说明</p>
<table>
<thead>
<tr>
<th><strong>选项</strong></th>
<th><strong>功能</strong></th>
</tr>
</thead>
<tbody><tr>
<td>-a</td>
<td>归档拷贝</td>
</tr>
<tr>
<td>-v</td>
<td>显示复制过程</td>
</tr>
</tbody></table>
<p>（2）案例实操</p>
<p>（3）把node01机器上的/kkb/soft目录同步到node02服务器的hadooop用户下的/kkb/目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -av /kkb/soft node02:/kkb/soft</span><br></pre></td></tr></table></figure>



<h6 id="3-通过rsync来封装分发脚本"><a href="#3-通过rsync来封装分发脚本" class="headerlink" title="3. 通过rsync来封装分发脚本"></a>3. 通过rsync来封装分发脚本</h6><p>我们可以通过rsync这个命令工具来实现脚本的分发，可以增量的将文件分发到我们所有其他的机器上面去</p>
<p>（1）需求：循环复制文件到所有节点的相同目录下</p>
<p>（2）需求分析：</p>
<p>（a）rsync命令原始拷贝：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -av /kkb/soft hadoop@node02:/kkb/soft</span><br></pre></td></tr></table></figure>

<p>（b）期望脚本使用方式：</p>
<p>xsync要同步的文件名称</p>
<p>（c）说明：在/home/hadoop/bin这个目录下存放的脚本，hadoop用户可以在系统任何地方直接执行。</p>
<p>（3）脚本实现</p>
<p>（a）在/home/hadoop目录下创建bin目录，并在bin目录下xsync创建文件，文件内容如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node01 ~]$ cd ~</span><br><span class="line">[hadoop@node01 ~]$ mkdir bin</span><br><span class="line">[hadoop@node01 bin]$ cd /home/hadoop/bin</span><br><span class="line">[hadoop@node01 ~]$ touch xsync</span><br><span class="line">[hadoop@node01 ~]$ vim xsync</span><br></pre></td></tr></table></figure>

<p>在该文件中编写如下代码</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash">1 获取输入参数个数，如果没有参数，直接退出</span></span><br><span class="line">pcount=$#</span><br><span class="line">if ((pcount==0)); then</span><br><span class="line">echo no args;</span><br><span class="line">exit;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">2 获取文件名称</span></span><br><span class="line">p1=$1</span><br><span class="line">fname=`basename $p1`</span><br><span class="line"></span><br><span class="line">echo $fname</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">3 获取上级目录到绝对路径</span></span><br><span class="line">pdir=`cd -P $(dirname $p1); pwd`</span><br><span class="line">echo $pdir</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">4 获取当前用户名称</span></span><br><span class="line">user=`whoami`</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">5 循环</span></span><br><span class="line">for((host=1; host&lt;4; host++)); do</span><br><span class="line">       echo ------------------- node0$host --------------</span><br><span class="line">       rsync -av $pdir/$fname $user@node0$host:$pdir</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<p>（b）修改脚本 xsync 具有执行权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node01 bin]$ cd ~/bin/</span><br><span class="line">[hadoop@node01 bin]$ chmod 777 xsync</span><br></pre></td></tr></table></figure>

<p>（c）调用脚本形式：xsync 文件名称</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node01 bin]$ xsync /home/hadoop/bin/</span><br></pre></td></tr></table></figure>



<p>注意：如果将xsync放到/home/hadoop/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下</p>
<h5 id="第六步：配置hadoop的环境变量"><a href="#第六步：配置hadoop的环境变量" class="headerlink" title="第六步：配置hadoop的环境变量"></a>第六步：配置hadoop的环境变量</h5><p>三台机器都要进行配置hadoop的环境变量</p>
<p>三台机器执行以下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HOME=/kkb/install/hadoop-3.1.4</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<p>配置完成之后生效</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>

<h5 id="第七步：格式化集群"><a href="#第七步：格式化集群" class="headerlink" title="第七步：格式化集群"></a>第七步：格式化集群</h5><ul>
<li><p>要启动 Hadoop 集群，需要启动 HDFS 和 YARN 两个集群。 </p>
</li>
<li><p>注意：首次启动HDFS时，必须对其进行格式化操作。本质上是一些清理和准备工作，因为此时的 HDFS 在物理上还是不存在的。<font color='red'>格式化操作只有在首次启动的时候需要，以后再也不需要了</font></p>
</li>
<li><p><font color='red'>node01执行一遍即可</font></p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>

<ul>
<li>或者</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop namenode –format</span><br></pre></td></tr></table></figure>

<ul>
<li>下图高亮表示格式化成功；</li>
</ul>
<p><img src="../images/assets/image-20201019211525368.png" alt="image-20201019211525368"></p>
<h5 id="第八步：集群启动"><a href="#第八步：集群启动" class="headerlink" title="第八步：集群启动"></a>第八步：集群启动</h5><ul>
<li>启动集群有两种方式：<ul>
<li>①脚本一键启动；</li>
<li>②单个进程逐个启动</li>
</ul>
</li>
</ul>
<h6 id="1-启动HDFS、YARN、Historyserver"><a href="#1-启动HDFS、YARN、Historyserver" class="headerlink" title="1. 启动HDFS、YARN、Historyserver"></a>1. 启动HDFS、YARN、Historyserver</h6><ul>
<li><p>如果配置了 etc/hadoop/workers 和 ssh 免密登录，则可以使用程序脚本启动所有Hadoop 两个集群的相关进程，在主节点所设定的机器上执行。</p>
</li>
<li><p>启动集群</p>
</li>
<li><p>主节点node01节点上执行以下命令</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br><span class="line">start-yarn.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 已过时mr-jobhistory-daemon.sh start historyserver</span></span><br><span class="line">mapred --daemon start historyserver</span><br></pre></td></tr></table></figure>

<ul>
<li>停止集群（主节点node01节点上执行）：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">stop-dfs.sh</span><br><span class="line">stop-yarn.sh </span><br><span class="line"><span class="meta">#</span><span class="bash"> 已过时 mr-jobhistory-daemon.sh stop historyserver</span></span><br><span class="line">mapred --daemon stop historyserver</span><br></pre></td></tr></table></figure>



<h6 id="2-单个进程逐个启动"><a href="#2-单个进程逐个启动" class="headerlink" title="2. 单个进程逐个启动"></a>2. 单个进程逐个启动</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在主节点上使用以下命令启动 HDFS NameNode： </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 已过时 hadoop-daemon.sh start namenode </span></span><br><span class="line">hdfs --daemon start namenode</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在主节点上使用以下命令启动 HDFS SecondaryNamenode： </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 已过时 hadoop-daemon.sh start secondarynamenode </span></span><br><span class="line">hdfs --daemon start secondarynamenode</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在每个从节点上使用以下命令启动 HDFS DataNode： </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 已过时 hadoop-daemon.sh start datanode</span></span><br><span class="line">hdfs --daemon start datanode</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在主节点上使用以下命令启动 YARN ResourceManager： </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 已过时 yarn-daemon.sh start resourcemanager </span></span><br><span class="line">yarn --daemon start resourcemanager</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在每个从节点上使用以下命令启动 YARN nodemanager： </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 已过时 yarn-daemon.sh start nodemanager </span></span><br><span class="line">yarn --daemon start nodemanager</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">以上脚本位于$HADOOP_HOME/sbin/目录下。如果想要停止某个节点上某个角色，只需要把命令中的start 改为stop 即可。</span><br></pre></td></tr></table></figure>

<h6 id="3-一键启动hadoop集群的脚本"><a href="#3-一键启动hadoop集群的脚本" class="headerlink" title="3. 一键启动hadoop集群的脚本"></a>3. 一键启动hadoop集群的脚本</h6><ul>
<li><p>为了便于一键启动hadoop集群，我们可以编写shell脚本</p>
</li>
<li><p>在node01服务器的/home/hadoop/bin目录下创建脚本</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node01 bin]$ cd /home/hadoop/bin/</span><br><span class="line">[hadoop@node01 bin]$ vim hadoop.sh</span><br></pre></td></tr></table></figure>

<ul>
<li>内容如下</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">case $1 in</span><br><span class="line">"start" )&#123;</span><br><span class="line"> source /etc/profile;</span><br><span class="line"> /kkb/install/hadoop-3.1.4/sbin/start-dfs.sh</span><br><span class="line"> /kkb/install/hadoop-3.1.4/sbin/start-yarn.sh</span><br><span class="line"> /kkb/install/hadoop-3.1.4/sbin/mr-jobhistory-daemon.sh start historyserver</span><br><span class="line"></span><br><span class="line">&#125;;;</span><br><span class="line">"stop")&#123;</span><br><span class="line"></span><br><span class="line"> /kkb/install/hadoop-3.1.4/sbin/stop-dfs.sh</span><br><span class="line"> /kkb/install/hadoop-3.1.4/sbin/stop-yarn.sh</span><br><span class="line"> /kkb/install/hadoop-3.1.4/sbin/mr-jobhistory-daemon.sh stop  historyserver</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<ul>
<li>修改脚本权限</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node01 bin]$ chmod 777 hadoop.sh</span><br><span class="line">[hadoop@node01 bin]$ ./hadoop.sh start  # 启动hadoop集群</span><br><span class="line">[hadoop@node01 bin]$ ./hadoop.sh stop   # 停止hadoop集群</span><br></pre></td></tr></table></figure>



<h5 id="第九步：验证集群是否搭建成功"><a href="#第九步：验证集群是否搭建成功" class="headerlink" title="第九步：验证集群是否搭建成功"></a>第九步：验证集群是否搭建成功</h5><h6 id="1-访问web-ui界面"><a href="#1-访问web-ui界面" class="headerlink" title="1. 访问web ui界面"></a>1. 访问web ui界面</h6><ul>
<li>hdfs集群访问地址</li>
</ul>
<p><a href="http://192.168.51.100:9870/" target="_blank" rel="noopener">http://192.168.51.100:9870/</a></p>
<ul>
<li>yarn集群访问地址</li>
</ul>
<p><a href="http://192.168.51.100:8088" target="_blank" rel="noopener">http://192.168.51.100:8088</a></p>
<ul>
<li>jobhistory访问地址：</li>
</ul>
<p><a href="http://192.168.51.100:19888" target="_blank" rel="noopener">http://192.168.51.100:19888</a></p>
<ul>
<li>若将linux的<code>/etc/hosts</code>文件的如下内容，添加到本机的hosts文件中(==ip地址根据自己的实际情况进行修改==)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.51.100 node01.kaikeba.com  node01</span><br><span class="line">192.168.51.110 node02.kaikeba.com  node02</span><br><span class="line">192.168.51.120 node03.kaikeba.com  node03</span><br></pre></td></tr></table></figure>

<ul>
<li><p>windows的hosts文件路径是<code>C:\Windows\System32\drivers\etc\hosts</code></p>
</li>
<li><p>mac的hosts文件是<code>/etc/hosts</code></p>
</li>
<li><p>那么，上边的web ui界面访问地址可以分别写程</p>
<ul>
<li><p>hdfs集群访问地址</p>
<p><a href="http://node01:9870/" target="_blank" rel="noopener">http://node01:9870/</a></p>
</li>
<li><p>yarn集群访问地址</p>
<p><a href="http://node01:8088" target="_blank" rel="noopener">http://node01:8088</a></p>
</li>
<li><p>jobhistory访问地址：</p>
<p><a href="http://node01:19888" target="_blank" rel="noopener">http://node01:19888</a></p>
</li>
</ul>
</li>
</ul>
<h6 id="2-所有机器查看进程脚本"><a href="#2-所有机器查看进程脚本" class="headerlink" title="2. 所有机器查看进程脚本"></a>2. 所有机器查看进程脚本</h6><ul>
<li><p>我们也可以通过jps在每台机器上面查看进程名称，为了方便我们以后查看进程，我们可以通过脚本一键查看所有机器的进程</p>
</li>
<li><p>在node01服务器的/home/hadoop/bin目录下创建文件xcall</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node01 bin]$ cd ~/bin/</span><br><span class="line">[hadoop@node01 bin]$ vim xcall</span><br></pre></td></tr></table></figure>



<ul>
<li>添加以下内容</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">params=$@</span><br><span class="line">for (( i=1 ; i &lt;= 3 ; i = $i + 1 )) ; do</span><br><span class="line">    echo ============= node0$i $params =============</span><br><span class="line">    ssh node0$i "source /etc/profile;$params"</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<ul>
<li>然后一键查看进程并分发该脚本</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod 777  /home/hadoop/bin/xcall</span><br><span class="line">xsync /home/hadoop/bin/</span><br></pre></td></tr></table></figure>

<ul>
<li>各节点应该启动的hadoop进程如下图</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xcall jps</span><br></pre></td></tr></table></figure>

<p><img src="../images/assets/image-20200513122314381.png" alt="image-20200513122314381"></p>
<h6 id="3-运行一个mr例子"><a href="#3-运行一个mr例子" class="headerlink" title="3. 运行一个mr例子"></a>3. 运行一个mr例子</h6><ul>
<li>任一节点运行pi例子</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node01 ~]$ hadoop jar &#x2F;kkb&#x2F;install&#x2F;hadoop-3.1.4&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.1.4.jar pi 5 5</span><br></pre></td></tr></table></figure>

<ul>
<li>最后计算出pi的近似值</li>
</ul>
<p><img src="../images/assets/image-20200522154422389.png" alt="image-20200522154422389"></p>
<p>==提醒：如果要关闭电脑时，清一定要按照以下顺序操作，否则集群可能会出问题==</p>
<ul>
<li><p>关闭hadoop集群</p>
</li>
<li><p>关闭虚拟机</p>
</li>
<li><p>关闭电脑</p>
</li>
</ul>
<h2 id="五、拓展点、未来计划、行业趋势"><a href="#五、拓展点、未来计划、行业趋势" class="headerlink" title="五、拓展点、未来计划、行业趋势"></a>五、拓展点、未来计划、行业趋势</h2><h2 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h2><h2 id="七、作业"><a href="#七、作业" class="headerlink" title="七、作业"></a>七、作业</h2><h2 id="八、互动问答"><a href="#八、互动问答" class="headerlink" title="八、互动问答"></a>八、互动问答</h2><h2 id="九、题库-本堂课知识点"><a href="#九、题库-本堂课知识点" class="headerlink" title="九、题库-本堂课知识点"></a>九、题库-本堂课知识点</h2> 
      <!-- reward -->
      
      <div id="reward-btn">
        打赏
      </div>
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>版权声明： </strong>
          本博客所有文章除特别声明外，著作权归作者所有。转载请注明出处！
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://chaoyang66.gitee.io/2020/09/29/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E8%AF%BE%E5%89%8D%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hadoop/" rel="tag">hadoop</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2020/11/27/vim%20%E5%91%BD%E4%BB%A4/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            vim 命令
          
        </div>
      </a>
    
    
      <a href="/2020/05/29/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3MySQL%E7%B4%A2%E5%BC%95B+Tree/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">深入理解MysqlB+Tree</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "SctsT8yefP0D7VSA3skojjQJ-gzGzoHsz",
    app_key: "m5U9PA8tUiK3NJFScBqsQ8pg",
    path: window.location.pathname,
    avatar: "mp",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2019-2020
        <i class="ri-heart-fill heart_icon"></i> 张朝阳
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        由 <a href="https://hexo.io" target="_blank">Hexo</a> 强力驱动
        <span class="division">|</span>
        主题 - <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></s>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src=''></script>
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/avatar.jpg" alt="奋斗的皮皮虾"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="http://shenyu-vip.lofter.com" target="_blank" rel="noopener">摄影</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E6%97%85%E8%A1%8C/">旅行</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2019/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechatpay.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Subtitle -->

<!-- Tocbot -->


<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: 'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto'
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>

<!-- Katex -->

<!-- busuanzi  -->


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<!-- ClickLove -->

<!-- ClickBoom1 -->

<script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script>

<script src="/js/clickBoom1.js"></script>


<!-- ClickBoom2 -->

<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
    <div id="music">
    
    
    
    <iframe frameborder="no" border="1" marginwidth="0" marginheight="0" width="200" height="86"
        src="//music.163.com/outchain/player?type=2&id=37653063&auto=1&height=66"></iframe>
</div>

<style>
    #music {
        position: fixed;
        right: 15px;
        bottom: 0;
        z-index: 998;
    }
</style>
    
  </div>
</body>

</html>